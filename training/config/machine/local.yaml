# Local machine configuration
name: local

# Hardware settings
batch_size: 8  # per GPU, per dataset
val_batch_size: 1  # per GPU (typically 1 for pose estimation)
num_workers: 1
gpus: 1

# Root directory
root_dir: /data/home/ssaricha/gigapose

# Logger backend (tensorboard or wandb)
logger_backend: tensorboard

# Callbacks
callbacks:
  checkpoint:
    _target_: pytorch_lightning.callbacks.ModelCheckpoint
    dirpath: ${checkpoint_dir}
    filename: '{epoch:03d}-{step}-{val/loss_total:.4f}'
    save_top_k: 3
    save_last: true
    monitor: val/loss_total
    mode: min
    # No every_n_epochs means: check every time val/loss_total is logged (every validation)
    save_on_train_epoch_end: false  # Save after validation completes
    verbose: true
  
  lr_monitor:
    _target_: pytorch_lightning.callbacks.LearningRateMonitor
    logging_interval: step

# PyTorch Lightning Trainer settings
trainer:
  _target_: pytorch_lightning.Trainer
  accelerator: gpu
  devices: ${machine.gpus}
  max_epochs: ${max_epochs}
  log_every_n_steps: ${log_every_n_steps}
  val_check_interval: ${val_check_interval}
  precision: 16-mixed  # Use mixed precision training
  gradient_clip_val: 1.0
  accumulate_grad_batches: 1
  num_sanity_val_steps: 0 #2
  
  # Logging
  enable_checkpointing: true
  enable_progress_bar: true
  enable_model_summary: true
